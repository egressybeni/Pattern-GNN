# Multi-GNN

This repository provides GNN training functionality for AML-E, ETH, and synthetic pattern detection datasets.

# Setup

First create the environment by running `conda env create -f environment_new.yml` and activate it (the new environment will be called multi_gnn). 

# AML datasets

The AML datasets can be doanloaded from Kaggle: https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml
Before using them, they have to be preprocessed with format_raw_transactions.py.

# ETH dataset

This dataset is currently not publicly available.

# Synthetic Subgraph Detection

This dataset is generated by ./train_helpers/simulator.py. The simulator generates 3 random graphs: train, validation, and test, each with `--sim_num_nodes` nodes and an average degree of `--sim_avg_degree`. The default graph generator is `--sim_generator 'chordal'`. The `--y_pretrain` argument is used to select the tasks. `'binary_all'` includes all the tasks from the paper, and `'binary_complex'` includes the complex tasks used in the appendix - C4, C5, C6, S-G, and B-C. Ck stands for directed k-cycle detection. S-G stamds for scatter-gather, and B-C stands for directed biclique detection.

# Model config files

./config/ contains config files for different models and datasets. In particular this is where the path to the dataset has to be defined (for AML and ETH experiments). The data paths are ignored for synthetic subgraph detection simulator.

./model_settings/ contains hyperparameter configurations files for each dataset. Each file contains hyperparameters for each GNN model. This files can be altered to use different hyperparameters.

Many parameters can also be changed by providing them as arguments. Parameters provided as arguments override the model_settings file. E.g., if --n_gnn_layers is set to 4, then a GNN with 4 layers will be trained regardless of what can be found in the relevant model_settings file.

# Example commands

Make sure you have updated the relevant config files as necessary.

Synthetic Subgraph Detection:
`python main.py --config_path ./configs/gin_SIM.json --log_folder_name ../logs/logs_SIM_001 --readout node --graph_simulator --y_pretrain binary_all --sim_num_nodes 8192 --sim_generator chordal --sim_avg_degree 6 --features raw --num_seeds 5 --model_settings ./model_settings/model_settings_SIM.json --unique_name SIM_001_gin --reverse_mp --ports --ego --disjoint`

AML:
`python main.py --config_path ./configs/gin_SJ.json --log_folder_name ../logs/logs_SJ_001 --readout edge --features raw --num_seeds 5 --model_settings ./model_settings/model_settings_SJ.json --unique_name SJ_001_gin --ports`

# Example Bash script

The script `run.sh` submits a single job. The script `run_benchmarks.py` calls `run.sh` several times to submit multiple jobs training different models on the same dataset.
Please edit the conda location in `run.sh` before running:
`source /{conda_environments_location}/bin/activate $conda`
Please also adapt `run_benchmarks.py` to your cluster, and to your needs.

# Results

The results will be found in the runs/ directory.



